# âš™ï¸ Kafka Complete Guide

*A visual, beginner-friendly guide to how Kafka handles data flow, reliability, and recovery â€” designed for ADHD brains.*

---

## ğŸ“‘ Table of Contents

1. [ğŸ§© Core Concepts & Architecture](#c-ore-concepts--architecture)#-core-concepts--architecture
2. [ğŸ›ï¸ Control Knobs & Configuration](#-control-knobs--configuration)
3. [ğŸ”’ Messaging Guarantees](#-messaging-guarantees)
4. [ğŸ’¾ Transactions & Storage Layout](#-transactions--storage-layout)
5. [ğŸš¨ Failures, Retries & DLQ Handling](#-failures-retries--dlq-handling)
6. [ğŸ§  Operational Tips & Monitoring](#-operational-tips--monitoring)
7. [ğŸ“˜ Quick Reference Cheat Sheet](#-quick-reference-cheat-sheet)

---

## ğŸ§© Core Concepts & Architecture

> ğŸ¯ *Mental Model:* Kafka is like a durable postal system for data â€” producers write messages, brokers deliver them, and consumers pick them up when ready.

![Kafka Architecture](/images/kafka-architecture.png)

```mermaid
flowchart LR
  subgraph Cluster
    P1["Partition 1<br>(Leader)"]
    P2["Partition 2<br>(Follower)"]
    P3["Partition 3<br>(Follower)"]
  end

  PRD["Producer"] -->|write| P1
  P1 -->|replicate| P2
  P1 -->|replicate| P3
  C1["Consumer 1"] -->|read| P1
  C2["Consumer 2"] -->|read| P2
```

| Concept            | Quick Definition  | Why It Matters                  |
| ------------------ | ----------------- | ------------------------------- |
| **Topic**          | Named data stream | Producers write, consumers read |
| **Partition**      | Slice of a topic  | Enables scaling                 |
| **Broker**         | Kafka server      | Stores partitions               |
| **Consumer Group** | Set of consumers  | Ensures balanced consumption    |
| **Offset**         | Message position  | Enables replay/resume           |
| **Replication**    | Data copies       | Survives failure                |

> ğŸ’¡ *Tip:* Kafka = â€œGoogle Drive for events.â€ Upload (produce) â†’ Store â†’ Download (consume).

[â¬†ï¸ Back to Top](#-kafka-complete-guide)

---

## ğŸ›ï¸ Control Knobs & Configuration

> âš™ï¸ *Goal:* Tune Kafka between durability ğŸ”’, performance âš¡, and availability ğŸŒ.

![Kafka Control Knobs](../images/kafka-replication.png)

```mermaid
flowchart LR
  P1["Producer 1"] --> T1["Topic A<br>(Partition 0â€“2)"]
  P2["Producer 2"] --> T1
  T1 -->|"replicated"| B1["Broker 1"]
  T1 -->|"replicated"| B2["Broker 2"]
  T1 -->|"replicated"| B3["Broker 3"]
  B1 -->|"deliver"| C1["Consumer 1"]
  B2 -->|"deliver"| C2["Consumer 2"]
  B3 -->|"deliver"| C3["Consumer 3"]
```

| Knob                      | Safer Setting          | Pros                   | Cons                |
| ------------------------- | ---------------------- | ---------------------- | ------------------- |
| **Replication Factor â†‘**  | 3+                     | Survives broker loss   | More disk & network |
| **min.insync.replicas â†‘** | 2+                     | Guarantees consistency | May reject writes   |
| **acks=all**              | Waits for all replicas | Strong durability      | Higher latency      |

> ğŸ’¡ *Tip:* Use `acks=all` + `min.insync.replicas=2` for production safety.
> âš ï¸ *Watch out:* Donâ€™t over-tighten these in dev â€” youâ€™ll slow yourself down.

[â¬†ï¸ Back to Top](#-kafka-complete-guide)

---

## ğŸ”’ Messaging Guarantees

> ğŸ§  *Question:* Whatâ€™s safer â€” sending fast or never losing data? Kafka lets you choose.

![Kafka Guarantees](../images/kafka-guarantees.png)

| Guarantee         | Behavior               | Use When           |
| ----------------- | ---------------------- | ------------------ |
| **At-most-once**  | Message may be lost    | Telemetry, metrics |
| **At-least-once** | Message delivered â‰¥1   | Notifications      |
| **Exactly-once**  | Message once, no dupes | Payments, orders   |

```mermaid
sequenceDiagram
  participant P as Producer
  participant K as Kafka
  participant C as Consumer
  P->>K: Send message
  K-->>C: Deliver message
  C->>K: Commit offset after processing
```

> ğŸ’¡ *Tip:* Start with *at-least-once* and dedupe by key.
> âš ï¸ *Watch out:* Exactly-once needs `enable.idempotence=true` and transactions.

[â¬†ï¸ Back to Top](#-kafka-complete-guide)

---

## ğŸ’¾ Transactions & Storage Layout

> ğŸ§­ *Goal:* Understand how Kafka achieves atomicity â€” all or nothing.

![Kafka Transactions](../images/kafka-transactions.png)

```mermaid
sequenceDiagram
  participant P as Producer (txn-enabled)
  participant CO as Txn Coordinator
  participant TP as Topic Partition
  participant C as Consumer (read_committed)
  P->>CO: BeginTransaction
  P->>TP: Write records
  TP-->>P: Acknowledge
  P->>CO: CommitTransaction
  CO->>TP: Append COMMIT marker
  Note over TP,C: LSO advances â€” committed data visible
  TP-->>C: Fetch records â‰¤ LSO
```

| Term              | Definition                         | Analogy             |
| ----------------- | ---------------------------------- | ------------------- |
| **LSO**           | Last Stable Offset                 | End of visible data |
| **HW / LEO**      | High Watermark / Replication point | Durability fence    |
| **Commit Marker** | Control record for visibility      | Checkmark at end    |

> ğŸ’¡ *Tip:* HW â‰  visible â€” visibility controlled by LSO.
> âš ï¸ *Watch out:* Long-running transactions block consumers until commit.

[â¬†ï¸ Back to Top](#-kafka-complete-guide)

---

## ğŸš¨ Failures, Retries & DLQ Handling

> ğŸ’¥ *Goal:* Handle retries safely and isolate bad data.

![Kafka Retries](../images/kafka-retries.png)

```mermaid
flowchart LR
  IN["Main Topic"]
  W["Worker"]
  OK["Success<br>Commit Offset"]
  R1["Retry 5s"]
  R2["Retry 1m"]
  R3["Retry 10m"]
  DLQ["Dead Letter Queue"]

  IN --> W
  W -->|success| OK
  W -->|fail| R1
  R1 --> W
  W -->|fail again| R2
  R2 --> W
  W -->|fail again| R3
  R3 --> W
  W -->|fail max| DLQ
```

> âš ï¸ *Watch out:* Poison messages can block partitions â€” isolate with tiered retries.
> ğŸ’¡ *Tip:* Add headers like `errorType`, `attempt`, `stacktrace` for DLQ analytics.

[â¬†ï¸ Back to Top](#-kafka-complete-guide)

---

## ğŸ§  Operational Tips & Monitoring

> ğŸ“Š *Goal:* Keep Kafka healthy and predictable.

| Area         | Metric                        | Why It Matters             |
| ------------ | ----------------------------- | -------------------------- |
| Producer     | `record-error-rate`           | Detect overload            |
| Consumer     | `lag`, `rebalance-count`      | Find bottlenecks           |
| Broker       | `under-replicated-partitions` | Detect instability         |
| Transactions | `txn-abort-rate`              | Reveal coordination issues |

> ğŸ’¡ *Tip:* Monitor **Consumer Lag vs LSO** â€” if it widens, consumers are behind commits.
> âš™ï¸ *Pro Move:* Auto-heal stuck consumers by rebalancing groups on lag threshold.

[â¬†ï¸ Back to Top](#-kafka-complete-guide)

---

## ğŸ“˜ Quick Reference Cheat Sheet

> ğŸ§¾ *Use this as your â€œfirst 10 seconds before panicâ€ guide.*

| Goal           | Key Settings                        | Notes                               |
| -------------- | ----------------------------------- | ----------------------------------- |
| Safe writes    | `acks=all`, `min.insync.replicas=2` | Most reliable baseline              |
| Deduplication  | `enable.idempotence=true`           | Avoid duplicate sends               |
| Exactly-once   | + `transactional.id`                | Enables atomic offset + sink commit |
| Debugging lag  | Check consumer offsets              | Look for rebalances                 |
| Retry strategy | Tiered topics                       | Avoid partition blocking            |

> ğŸ’¡ *Tip:* Kafka doesnâ€™t lose data â€” you just have to tell it how patient to be.
> ğŸ§© *Mnemonic:* â€œAcks, Replicas, Transactions = ART of durability.â€

[â¬†ï¸ Back to Top](#-kafka-complete-guide)
